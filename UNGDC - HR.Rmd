---
title: "UNGDC"
author: 
- affiliation: Hertie School
  email: n.locher@mpp.hertie-school.org
  name: Nina Locher
- affiliation: Hertie School
  email: d.patino@mpp.hertie-school.org
  name: Daniela Patiño Piñeros
- affiliation: Hertie School
  email: j.uribe-piedrahita@mpp.hertie-school.org
  name: Juan Gonzalo Uribe Piedrahita
date: "21/10/2019"
output: html_document
---

```{r setup, include=FALSE}
library(Amelia)
library(gridExtra)
library(quanteda)
library(tibble)
library(tidyverse)
library(zip)

#Sentiment Dictionary
library(syuzhet)
```


### UNGDC data
```{r}
dir.create(temp <- tempfile())

urlungdc<-'https://dataverse.harvard.edu/api/access/datafile/:persistentId?persistentId=doi:10.7910/DVN/0TJX8Y/PZUURT'

#MacOs
#download.file(urlungdc, paste0(temp, '/PZUURT.zip'),exdir = temp) 

#Win
download.file(urlungdc, paste0(temp, '/PZUURT.zip'),exdir = temp, mode="wb") 

unzip(paste0(temp, '/PZUURT.zip'), exdir = temp)

root_folder <- paste0(temp,'/Converted sessions/')

filelist <-list.files(path = root_folder, pattern = '*.txt', recursive = TRUE)
filenames <- basename(filelist)
ungdc_files <- data.frame(t(sapply(strsplit(filenames, '_'), 
                 function(x) c(x[1], x[2], substr(x[3], 1, 4)))))
colnames(ungdc_files) <- c('country', 'number', 'year')
ungdc_files$text <- sapply(paste0(root_folder, filelist), function(x) readChar(x, file.info(x)$size))
ungdc_files<-as.data.frame(ungdc_files)
ungdc_files$number<-as.integer(as.character(ungdc_files$number))
ungdc_files$year<-as.integer(as.character(ungdc_files$year))
ungdc_files$country<-as.character(ungdc_files$country)
ungdc_files$text<-gsub("\n"," ",ungdc_files$text)
ungdc_files$text<-gsub("\t"," ",ungdc_files$text)
ungdc_files$text<-gsub("\r"," ",ungdc_files$text)
ungdc_files$text<-gsub('"',"",ungdc_files$text)

ungdc_files<-ungdc_files[!ungdc_files$year< 1976, ]

unlink(temp)
rm(temp)
rm(filelist)
rm(filenames)
rm(urlungdc)
rm(root_folder)
```

### UNGDC data
```{r}
load(url("http://www.politicalterrorscale.org/Data/Files/PTS-2019.RData"))

PTS_2019<-arrange(PTS_2019,Country,Year)
PTS_2019<-PTS_2019 %>% 
  group_by(Country) %>% 
  mutate(.,PTS_S_ch=c(NA,diff(PTS_S)))

PTS_2019<-mutate(PTS_2019,PTS_S_var= ifelse(PTS_S_ch>0,1,0))

PTS_2019<-PTS_2019 %>% 
  group_by(Country) %>% 
  mutate(.,PTS_H_ch=c(NA,diff(PTS_H)))

PTS_2019<-mutate(PTS_2019,PTS_H_var= ifelse(PTS_H_ch>0,1,0))


PTS_2019<-PTS_2019 %>% 
  group_by(Country) %>% 
  mutate(.,PTS_A_ch=c(NA,diff(PTS_A)))

PTS_2019<-mutate(PTS_2019,PTS_A_var= ifelse(PTS_A_ch>0,1,0))
```

###Misssing values analysis
```{r}

missmap(PTS_2019, main = "Missing values PTS")

missmap(ungdc_files, main = "Missing values UNGDC")
```


```{r}
dfungdc <- ungdc_files

#Corpus
c_dfungc<-dfungdc
c_dfungc$text<-dfm(c_dfungc$text)


c1_dfungc<-dfungdc
c1_dfungc$text<-dfm(c1_dfungc$text, remove = stopwords("en"))


c2_dfungc<-dfungdc
c2_dfungc$text<-dfm(c2_dfungc$text, remove = stopwords("en"), remove_punct = TRUE)

c3_dfungc<-dfungdc
c3_dfungc$text<-dfm(c3_dfungc$text, remove = stopwords("en"), remove_punct = TRUE, stem = TRUE)

c4_dfungc<-dfungdc
c4_dfungc$text<-dfm(c4_dfungc$text, remove_punct = TRUE, ngrams = 2)

df_c_dfungc<-topfeatures(c_dfungc$text) %>% 
  as.data.frame() %>% 
  `colnames<-`("n") %>% 
  rownames_to_column("Word") %>% 
  mutate(Words = fct_reorder(Word, n))

g_df_c_dfungc<- ggplot(df_c_dfungc,aes(x=Words,y=n))+
  geom_col(show.legend = FALSE) +
  coord_flip() +
  ggtitle("Original")+
  theme(plot.title = element_text(size = 8))


df_c1_dfungc<-topfeatures(c1_dfungc$text) %>% 
  as.data.frame() %>% 
  `colnames<-`("n") %>% 
  rownames_to_column("Word") %>% 
  mutate(Words = fct_reorder(Word, n))

g_df_c1_dfungc<- ggplot(df_c1_dfungc,aes(x=Words,y=n))+
  geom_col(show.legend = FALSE) +
  coord_flip() +
  ggtitle("-Stop Words")+
  theme(plot.title = element_text(size = 8))

df_c2_dfungc<-topfeatures(c2_dfungc$text) %>% 
  as.data.frame() %>% 
  `colnames<-`("n") %>% 
  rownames_to_column("Word") %>% 
  mutate(Words = fct_reorder(Word, n))

g_df_c2_dfungc<- ggplot(df_c2_dfungc,aes(x=Words,y=n))+
  geom_col(show.legend = FALSE) +
  coord_flip() +
  ggtitle("-StopWords-Punctuation")+
  theme(plot.title = element_text(size = 8))

df_c3_dfungc<-topfeatures(c3_dfungc$text) %>% 
  as.data.frame() %>% 
  `colnames<-`("n") %>% 
  rownames_to_column("Word") %>% 
  mutate(Words = fct_reorder(Word, n))

g_df_c3_dfungc<- ggplot(df_c3_dfungc,aes(x=Words,y=n))+
  geom_col(show.legend = FALSE) +
  coord_flip() +
  ggtitle("-StopWords-Punc+Stemming")+
  theme(plot.title = element_text(size = 8,hjust = 0))

df_c4_dfungc<-topfeatures(c4_dfungc$text) %>% 
  as.data.frame() %>% 
  `colnames<-`("n") %>% 
  rownames_to_column("Word") %>% 
  mutate(Words = fct_reorder(Word, n))

g_df_c4_dfungc<- ggplot(df_c4_dfungc,aes(x=Words,y=n))+
  geom_col(show.legend = FALSE) +
  coord_flip() +
  ggtitle("-Punctuation +ngrams=2")+
  theme(plot.title = element_text(size = 8,hjust = 0))

grid.arrange(g_df_c_dfungc, g_df_c1_dfungc, g_df_c2_dfungc,g_df_c3_dfungc,g_df_c4_dfungc,
             nrow = 2,
             top="Word Count Review")
```

<<<<<<< Updated upstream
=======
###Misssing values analysis

#Dictionary Analysis and KWIC (25-word context)

## Stage 1 - Human Rights terms

Creating compound tokens from the key terms identified:
 
```{r}

listHHRR <- list( c("Human", "Rights")) 
```
 

```{r}
token.compound <- tokens_compound(tok.r, listHHRR, valuetype = "fixed", concatenator = "_")
```

Creating the dictionary object of Human Rights terms:

```{r}
HHRR_dict <- dictionary(list(Human.Rights=c("Human Rights", "Rights")))
```

## Look up Human Rights term counts

Looking up and counting terms from Human Rights in the DFM

```{r}
?dfm_lookup
```

DFM_LOOKUP --> Apply a dictionary (HHRR) to a dfm by looking up all dfm features for matches in a a set of dictionary values, and replace those features with a count of the dictionary's keys.

```{r}
dfm_1 <- dfm(token.compound)

HHRR_dfm <- dfm_lookup(dfm_1, HHRR_dict, valuetype = "fixed")
```

```{r}
head(HHRR_dfm)
```

Data Frame

```{r}
#creating a data frame --> CHECK IF THIS IS NECESARY IN THIS POINT OF THE PROJECT
Human.Rights <- convert(HHRR_dfm, to = "data.frame")

#converting documentID into two columns - country and year
HHRR_counts <- Human.Rights %>%
  separate(document, c("country", "year"), "_")

#year as numeric
HHRR_counts$year <- as.numeric(HHRR_counts$year)

HHRR_counts <- plyr::rename(HHRR_counts, c("Human.Rights"="HHRR"))
```

```{r}
head(HHRR_counts)
```



## Presentation of results

### Map for 2017 of HHRR

Keeping only country-years with at least one mention of HHRR


```{r}
mentions_HHRR <- subset(HHRR_counts, "human rights"!=0)
```

```{r}
head(mentions_HHRR)
```



Error in joinCountryData2Map --> check the packages

```{r}

map <- joinCountryData2Map(subset(mentions_HHRR, year==2017), joinCode="ISO3", nameJoinColumn="country")

new_world <- subset(map, continent != "Antarctica")

pdf("worldmap_2017_health.pdf", width = 7, height = 3)

par(mai=c(0,0,0.2,0),xaxs="i",yaxs="i")

mapParams <- mapCountryData(new_world, nameColumnToPlot="HHRR", 
                            mapTitle="2017 UN General Debate: HHRR", 
                            catMethod = "categorical", 
                            colourPalette = "heat", 
                            oceanCol = "lightblue", 
                            missingCountryCol = "white", 
                            addLegend="FALSE")

do.call( addMapLegendBoxes, c(mapParams,title="Number of mentions", x = "left", cex=0.5))

dev.off()
```

## Time series of total counts plot

### Total counts

```{r}
# calculating the total number of mentions by year
sum <- summarise(group_by(country2Region(count), year), count = sum(Human.Rights), mean = mean(Human.Rights))

ggplot(sum, aes(x=year)) +
  theme_bw() +
  geom_line(aes(y= HHRR_count), colour = "blue", alpha = 0.9) +
  ylab("Total number of references per UNGD session") + xlab("Year") + 
#  scale_y_continuous(limits=c(0, 140), breaks = c(1, 50, 100, 134)) +
  scale_x_continuous(limits=c(1970, 2017), breaks = c(1970, 1988, 2000, 2009,2014, 2017)) +
   annotate("text", x = 1993, y = 250, label = "Human Rights", colour = "blue")

```



>>>>>>> Stashed changes

### add LSD Lexicoder Sentiment Dictionary


install.packages("quanteda")
install.packages("readtext")
install.packages("devtools")
devtools::install_github("quanteda/quanteda.corpora")
packageVersion("quanteda")
install.packages("newsmap")
install.packages("tm")
install.packages("NLP")
install.packages("tibble")
install.packages("slam")


example(data_dictionary_LSD2015)

### add H3 Dictionaries

```{r}
dict_intmilitary <- read.delim("https://raw.githubusercontent.com/openeventdata/tabari_dictionaries/master/IntMilitGroups.090831.actors.txt")

```

### Create Human Rights Dictionary

```{r}
library(quanteda)

#create human rights lists from the three sources

HRlistFariss <- list( c("kill"), c("forc"), c("arm"), c("group"), c("civilian"), c("human"), c("secur"), c("disappear"), c("attack"), c("execut") , c("tortur"), c("member"), c("includ"), c("arrest"), c("prison"), c("polit"), c("amnesti"), c("trial"), c("releas"), c("imprison"), c("sentenc"), c("charg"), c("conscience"), c("polic"), c("offic"), c("illtreat"), c("death"), c("court"), c("alleg"), c("law"), c("service"), c("concern"), c("appeal"), c("servic"), c("committee"),    c("militari"), c("area"), c("continu"), c("section"), c("state"), c("dure"), c("arrest"), c("accord"), c("offici"), c("presid"), c("opposit"), c("howev"), c("parti"), c("author"), c("law"), c("provid"), c("gener"), c("public"), c("constitut"), c("employ"), c("women"), c("right"), c("respect"), c("freedom"), c("prohibit"), c("case"), c("ngo"), c("tortur"), c("gener"), c("labor"), c("detain"), c("releas"), c("elect"), c("local"), c("presidenti"), c("region"), c("mani"), c("regim"), c("nation"), c("ethnic"), c("union"), c("practic"), c("work"), c("foreign"), c("children"), c("investig"), c("relig"), c("islam"), c("roma"), c("worker"), c("traffic"), c("feder"), c("parliament"))

HRlistGreene <- list(c("committed"), c("victims"), c("populations"), c("scale"), c("armed"), c("army"), c("commanders"), c("conscripted"), c("assassinations"), c("massacres"), c("internally", "displaced"), c("food"), c("humanitarian"), c("landmines"), c("money"), c("raped"), c("disappearances"), c("frequently"), c("numerous"), c("widespread"), c("common"), c("regularly"), c("routinely"), c("systematic"), c("extensive"))

HRlistWatanabe <- list(c("human", "rights"), c("violat"), c("race"), c("dignit"), c("protect"), c("citizen"), c("educat"), c("child"), c("refugee"), c("communit"), c("people"), c("responsibl"), c("health"), c("world"))

HRlist <- do.call(c, list(HRlistFariss, HRlistGreene, HRlistWatanabe))
summary(HRlist)

#create dictionaries from the three sources

dict_HRFariss <- dictionary(list(human_rightsF = c("kill", "forc", "arm", "group", "civilian", "human", "secur", "disappear", "attack", "execut" , "tortur", "member", "includ", "arrest", "prison", "polit", "amnesti", "trial", "releas", "imprison", "sentenc", "charg", "conscience", "polic", "offic", "illtreat", "death", "court", "alleg", "law", "service", "concern", "appeal", "servic", "committee", "militari", "area", "continu", "section", "state", "dure", "arrest", "offici", "presid", "opposit", "parti", "author", "law", "provid", "gener", "public", "constitut", "employ", "women", "right", "respect", "freedom", "prohibit", "case", "ngo", "tortur", "gener", "labor", "detain", "releas", "elect", "local", "presidenti", "region", "mani", "regim", "nation", "ethnic", "union", "practic", "work", "foreign", "children", "investig", "relig", "islam", "roma", "worker", "traffic", "feder", "parliament")))

dict_HRGreene <- dictionary(list(human_rightsG = c("commit", "victim", "popul", "scale", "armi", "command", "conscript", "assassin", "massacr", "intern_displac", "food", "humanitarian", "landmin", "money", "rape", "disappear", "widespread", "systemat", "extens")))

#checking the stemmed version of dict_HRGreene
char_HRGreene <- as.character(dict_HRGreene)
toks_HRGreene <- tokens(char_HRGreene)
toks_HRGreene
remove_HRGreene <- tokens(toks_HRGreene, remove_punct = TRUE)
remove_HRGreene
tokens_wordstem(remove_HRGreene)

dict_HRWatanabe <- dictionary(list(human_rightsW = c("human_rights", "violat", "race", "dignit", "protect", "citizen", "educat", "child", "refugee", "communit", "people", "responsibl", "health", "world")))

#combine the dictionaries
HRdict <- c(dict_HRGreene["human_rightsG"], dict_HRFariss["human_rightsF"], dict_HRWatanabe["human_rightsW"])
HRdict

###please check if all words should be used
```

ADD actors and agents dictionary 

```{r}
?dictionary
?download.file
?load

tempagents <- tempfile()
fileagents <- download.file("", tempagents)
X <- read.csv(url())
fileagents <- read.csv("https://raw.githubusercontent.com/juribep5/tadaproject/master/agents.csv", header = TRUE, sep = ",")
fileagents = subset(fileagents, select = -c(note))
colnames(fileagents) <- c("agent", "topic")
summary(fileagents)
str(fileagents)
listagents <- list
list

dictagents <- dictionary(list(agents = fileagents, tolower = TRUE))
fileagents
str(listagents)











```

ungd_files <- readtext("Converted sessions/*", 
                                 docvarsfrom = "filenames", 
                                 dvsep="_", 
                                 docvarnames = c("Country", "Session", "Year"))


ungd_files$doc_id <- str_replace(ungd_files$doc_id , ".txt", "") %>%
   str_replace(. , "_\\d{2}", "")



Descriptive analysis with human rights dictionary
--> this needs a tokenized and corpus mode of our files so I will leave this here


