---
title: "UNGDC"
author: 
- affiliation: Hertie School
  email: n.locher@mpp.hertie-school.org
  name: Nina Locher
- affiliation: Hertie School
  email: d.patino@mpp.hertie-school.org
  name: Daniela Patiño Piñeros
- affiliation: Hertie School
  email: j.uribe-piedrahita@mpp.hertie-school.org
  name: Juan Gonzalo Uribe Piedrahita
date: "21/10/2019"
output: html_document
---

```{r setup, include=FALSE}
library(Amelia)
library(gridExtra)
library(quanteda)
library(tibble)
library(tidyverse)
library(zip)

#Sentiment Dictionary
library(syuzhet)
```


### PTS and UNGDC data
```{r}

dir.create(temp <- tempfile())

urlungdc<-'https://dataverse.harvard.edu/api/access/datafile/:persistentId?persistentId=doi:10.7910/DVN/0TJX8Y/PZUURT'
download.file(urlungdc, paste0(temp, '/PZUURT.zip'), 
              exdir = temp)
unzip(paste0(temp, '/PZUURT.zip'), exdir = temp)

root_folder <- paste0(temp,'/Converted sessions/')

filelist <-list.files(path = root_folder, pattern = '*.txt', recursive = TRUE)
filenames <- basename(filelist)
ungdc_files <- data.frame(t(sapply(strsplit(filenames, '_'), 
                 function(x) c(x[1], x[2], substr(x[3], 1, 4)))))
colnames(ungdc_files) <- c('country', 'number', 'year')
ungdc_files$text <- sapply(paste0(root_folder, filelist), function(x) readChar(x, file.info(x)$size))
ungdc_files<-as.data.frame(ungdc_files)
ungdc_files$number<-as.integer(as.character(ungdc_files$number))
ungdc_files$year<-as.integer(as.character(ungdc_files$year))
ungdc_files$country<-as.character(ungdc_files$country)
ungdc_files$text<-gsub("\n"," ",ungdc_files$text)
ungdc_files$text<-gsub("\t"," ",ungdc_files$text)
ungdc_files$text<-gsub("\r"," ",ungdc_files$text)
ungdc_files$text<-gsub('"',"",ungdc_files$text)

ungdc_files<-ungdc_files[!ungdc_files$year< 1976, ]


load(url("http://www.politicalterrorscale.org/Data/Files/PTS-2019.RData"))

unlink(temp)
rm(temp)
rm(filelist)
rm(filenames)
rm(urlungdc)
rm(root_folder)
```

###Misssing values analysis
```{r}

missmap(PTS_2019, main = "Missing values PTS")

missmap(ungdc_files, main = "Missing values UNGDC")
```



```{r}
dfungdc <- ungdc_files

#Corpus
c_dfungc<-dfungdc
c_dfungc$text<-dfm(c_dfungc$text)


c1_dfungc<-dfungdc
c1_dfungc$text<-dfm(c1_dfungc$text, remove = stopwords("en"))


c2_dfungc<-dfungdc
c2_dfungc$text<-dfm(c2_dfungc$text, remove = stopwords("en"), remove_punct = TRUE)

c3_dfungc<-dfungdc
c3_dfungc$text<-dfm(c3_dfungc$text, remove = stopwords("en"), remove_punct = TRUE, stem = TRUE)

c4_dfungc<-dfungdc
c4_dfungc$text<-dfm(c4_dfungc$text, remove_punct = TRUE, ngrams = 2)

df_c_dfungc<-topfeatures(c_dfungc$text) %>% 
  as.data.frame() %>% 
  `colnames<-`("n") %>% 
  rownames_to_column("Word") %>% 
  mutate(Words = fct_reorder(Word, n))

g_df_c_dfungc<- ggplot(df_c_dfungc,aes(x=Words,y=n))+
  geom_col(show.legend = FALSE) +
  coord_flip() +
  ggtitle("Original")+
  theme(plot.title = element_text(size = 8))


df_c1_dfungc<-topfeatures(c1_dfungc$text) %>% 
  as.data.frame() %>% 
  `colnames<-`("n") %>% 
  rownames_to_column("Word") %>% 
  mutate(Words = fct_reorder(Word, n))

g_df_c1_dfungc<- ggplot(df_c1_dfungc,aes(x=Words,y=n))+
  geom_col(show.legend = FALSE) +
  coord_flip() +
  ggtitle("-Stop Words")+
  theme(plot.title = element_text(size = 8))

df_c2_dfungc<-topfeatures(c2_dfungc$text) %>% 
  as.data.frame() %>% 
  `colnames<-`("n") %>% 
  rownames_to_column("Word") %>% 
  mutate(Words = fct_reorder(Word, n))

g_df_c2_dfungc<- ggplot(df_c2_dfungc,aes(x=Words,y=n))+
  geom_col(show.legend = FALSE) +
  coord_flip() +
  ggtitle("-StopWords-Punctuation")+
  theme(plot.title = element_text(size = 8))

df_c3_dfungc<-topfeatures(c3_dfungc$text) %>% 
  as.data.frame() %>% 
  `colnames<-`("n") %>% 
  rownames_to_column("Word") %>% 
  mutate(Words = fct_reorder(Word, n))

g_df_c3_dfungc<- ggplot(df_c3_dfungc,aes(x=Words,y=n))+
  geom_col(show.legend = FALSE) +
  coord_flip() +
  ggtitle("-StopWords-Punc+Stemming")+
  theme(plot.title = element_text(size = 8,hjust = 0))

df_c4_dfungc<-topfeatures(c4_dfungc$text) %>% 
  as.data.frame() %>% 
  `colnames<-`("n") %>% 
  rownames_to_column("Word") %>% 
  mutate(Words = fct_reorder(Word, n))

g_df_c4_dfungc<- ggplot(df_c4_dfungc,aes(x=Words,y=n))+
  geom_col(show.legend = FALSE) +
  coord_flip() +
  ggtitle("-Punctuation +ngrams=2")+
  theme(plot.title = element_text(size = 8,hjust = 0))

grid.arrange(g_df_c_dfungc, g_df_c1_dfungc, g_df_c2_dfungc,g_df_c3_dfungc,g_df_c4_dfungc,
             nrow = 2,
             top="Word Count Review")
```

<<<<<<< Updated upstream
=======
###Misssing values analysis

#Dictionary Analysis and KWIC (25-word context)

## Stage 1 - Human Rights terms

Creating compound tokens from the key terms identified:
 
```{r}

listHHRR <- list( c("Human", "Rights")) 
```
 

```{r}
token.compound <- tokens_compound(tok.r, listHHRR, valuetype = "fixed", concatenator = "_")
```

Creating the dictionary object of Human Rights terms:

```{r}
HHRR_dict <- dictionary(list(Human.Rights=c("Human Rights", "Rights")))
```

## Look up Human Rights term counts

Looking up and counting terms from Human Rights in the DFM

```{r}
?dfm_lookup
```

DFM_LOOKUP --> Apply a dictionary (HHRR) to a dfm by looking up all dfm features for matches in a a set of dictionary values, and replace those features with a count of the dictionary's keys.

```{r}
dfm_1 <- dfm(token.compound)

HHRR_dfm <- dfm_lookup(dfm_1, HHRR_dict, valuetype = "fixed")
```

```{r}
head(HHRR_dfm)
```

Data Frame

```{r}
#creating a data frame --> CHECK IF THIS IS NECESARY IN THIS POINT OF THE PROJECT
Human.Rights <- convert(HHRR_dfm, to = "data.frame")

#converting documentID into two columns - country and year
HHRR_counts <- Human.Rights %>%
  separate(document, c("country", "year"), "_")

#year as numeric
HHRR_counts$year <- as.numeric(HHRR_counts$year)

HHRR_counts <- plyr::rename(HHRR_counts, c("Human.Rights"="HHRR"))
```

```{r}
head(HHRR_counts)
```



## Presentation of results

### Map for 2017 of HHRR

Keeping only country-years with at least one mention of HHRR


```{r}
mentions_HHRR <- subset(HHRR_counts, "human rights"!=0)
```

```{r}
head(mentions_HHRR)
```



Error in joinCountryData2Map --> check the packages

```{r}

map <- joinCountryData2Map(subset(mentions_HHRR, year==2017), joinCode="ISO3", nameJoinColumn="country")

new_world <- subset(map, continent != "Antarctica")

pdf("worldmap_2017_health.pdf", width = 7, height = 3)

par(mai=c(0,0,0.2,0),xaxs="i",yaxs="i")

mapParams <- mapCountryData(new_world, nameColumnToPlot="HHRR", 
                            mapTitle="2017 UN General Debate: HHRR", 
                            catMethod = "categorical", 
                            colourPalette = "heat", 
                            oceanCol = "lightblue", 
                            missingCountryCol = "white", 
                            addLegend="FALSE")

do.call( addMapLegendBoxes, c(mapParams,title="Number of mentions", x = "left", cex=0.5))

dev.off()
```

## Time series of total counts plot

### Total counts

```{r}
# calculating the total number of mentions by year
sum <- summarise(group_by(country2Region(count), year), count = sum(Human.Rights), mean = mean(Human.Rights))

ggplot(sum, aes(x=year)) +
  theme_bw() +
  geom_line(aes(y= HHRR_count), colour = "blue", alpha = 0.9) +
  ylab("Total number of references per UNGD session") + xlab("Year") + 
#  scale_y_continuous(limits=c(0, 140), breaks = c(1, 50, 100, 134)) +
  scale_x_continuous(limits=c(1970, 2017), breaks = c(1970, 1988, 2000, 2009,2014, 2017)) +
   annotate("text", x = 1993, y = 250, label = "Human Rights", colour = "blue")

```




>>>>>>> Stashed changes

### add LSD Lexicoder Sentiment Dictionary


install.packages("quanteda")
install.packages("readtext")
install.packages("devtools")
devtools::install_github("quanteda/quanteda.corpora")
packageVersion("quanteda")
install.packages("newsmap")
install.packages("tm")
install.packages("NLP")
install.packages("tibble")
install.packages("slam")

library(quanteda)
example(data_dictionary_LSD2015)

### add Syuzhet dictionary

install.packages("syuzhet")
devtools::install_github("mjockers/syuzhet")

