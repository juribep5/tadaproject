---
title: "UNGDC"
author: "JGUP"
date: "10/10/2019"
output: html_document
---

```{r setup, include=FALSE}
library(zip)


```


### PTS and UNGDC data

```{r}

#filelist <- list.files(path = root_folder, pattern = '*.txt', recursive = TRUE)
#filenames <- basename(filelist)
#ungdc_files <- data.frame(t(sapply(strsplit(filenames, '_'), 
#                 function(x) c(x[1], x[2], substr(x[3], 1, 4)))))
#colnames(ungdc_files) <- c('country', 'number', 'year')
#ungdc_files$text <- sapply(paste0(root_folder, filelist), function(x) readChar(x, file.info(x)$size))

#load(url("http://www.politicalterrorscale.org/Data/Files/PTS-2019.RData"))

```

# tadaproject
Human Rights in the UNGA

Using the code of the  The Lancet Countdown report: Nick Watts et al. (2018). "The 2018 report of the Lancet Countdown on health and climate change: shaping the health of nations for centuries to come." The Lancet, 392(10163): 2479-2514. With the UNGA Corpus.

#Data

Loading data from the UNGDC data


```{r message=FALSE}
#Loading packages and data
library(readtext)
library(quanteda)
library(dplyr)
library(tidyr)
library(stringr)
library(ggplot2)
library(rworldmap)
library(RColorBrewer)
library(haven)
library(readxl)
```

### UNGDC data
```{r}
#Upload UNGDC data
dir.create(temp <- tempfile())
urlungdc<-'https://dataverse.harvard.edu/api/access/datafile/:persistentId?persistentId=doi:10.7910/DVN/0TJX8Y/PZUURT'
download.file(urlungdc, paste0(temp, '/PZUURT.zip'), mode="wb",
              exdir = temp)
unzip(paste0(temp, '/PZUURT.zip'), exdir = temp)

ungd_files <- readtext(paste0(temp, "/Converted sessions/*"),
                       docvarsfrom = "filenames", 
                       dvsep="_", 
                       docvarnames = c("Country", "Session", "Year"))
head(ungd_files)

ungd_files$doc_id <- str_replace(ungd_files$doc_id , ".txt", "") %>%
   str_replace(. , "_\\d{2}", "")

unlink(temp)
rm(temp)
#rm(filelist)
#rm(filenames)
rm(urlungdc)

```

### PTS data
```{r}
load(url("http://www.politicalterrorscale.org/Data/Files/PTS-2019.RData"))
PTS_2019<-arrange(PTS_2019,Country,Year)
PTS_2019<-PTS_2019 %>% 
  group_by(Country) %>% 
  mutate(.,PTS_S_ch=c(NA,diff(PTS_S)))
PTS_2019<-mutate(PTS_2019,PTS_S_var= ifelse(PTS_S_ch>0,1,0))
PTS_2019<-PTS_2019 %>% 
  group_by(Country) %>% 
  mutate(.,PTS_H_ch=c(NA,diff(PTS_H)))
PTS_2019<-mutate(PTS_2019,PTS_H_var= ifelse(PTS_H_ch>0,1,0))
PTS_2019<-PTS_2019 %>% 
  group_by(Country) %>% 
  mutate(.,PTS_A_ch=c(NA,diff(PTS_A)))
PTS_2019<-mutate(PTS_2019,PTS_A_var= ifelse(PTS_A_ch>0,1,0))
```

merging the datasets UNGD and PTS
```{r}
install.packages("compareDF")
library(compareDF)

df_PTS_2019 <- data.frame(PTS_2019)
df_ungd_files <- data.frame(ungd_files)

print(PTS_2019)
print(ungd_files)
comp_year <- compare_df(ungd_files$Year, PTS_2019$Year, c("Year"))
list(ungd_files$Year)
all(df_ungd_files$Year == df_PTS_2019$Year)


###DELETE first 8 YEARS how???
#compare years
PTS_2019 %>%
      group_by(Year) %>%
      summarise(n = n())
ungd_files %>%
      group_by(Year) %>%
      summarise(n = n())
#ungd_files$Year<-as.integer(as.character(ungd_files$Year))
ungd_files1976 <- ungd_files[-(1970:1975)]
ungd_files1976$Year

PTS_2019 %>%
      group_by(Year) %>%
      summarise(n = n())

#compare country
PTS_2019 %>%
      group_by(MergeCountry) %>%
      summarise(n = n())
ungd_files %>%
      group_by(MergeCountry) %>%
      summarise(n = n())

colnames(ungd_files)[colnames(ungd_files)=="Country"] <- "MergeCountry"
colnames(PTS_2019)[colnames(PTS_2019)=="WordBank_Code_A"] <- "MergeCountry"

merge_PTS_ungd <- merge(PTS_2019, ungd_files, by = c('Year','MergeCountry'), all=TRUE)
merge_PTS_ungd1976 <- subset(merge_PTS_ungd, !merge_PTS_ungd$Year<1976)
NA_PTS_ungd1976 <- subset(merge_PTS_ungd1976, is.na(merge_PTS_ungd1976$MergeCountry))
mergeNA_PTS_ungd_1976 <- subset(merge_PTS_ungd1976, !is.na(merge_PTS_ungd1976$MergeCountry))
tail(mergeNA_PTS_ungd_1976)
```

##Creating corpus object(s)
```{r}
ungd_corpus <- corpus(ungd_files, text_field = "text") 
ungdc.1990 <- corpus_subset(ungd_corpus, Year>1990)

```


#Pre-processing

Tokenizing corpus.

```{r}
#Tokenization and basic pre-processing
toks_UNGD <- tokens(ungd_corpus, what = "word",
              remove_punct = TRUE,
              remove_symbols = TRUE,
              remove_numbers = TRUE,
              remove_twitter = TRUE,
              remove_url = TRUE,
              remove_hyphens = FALSE,
              verbose = TRUE, 
              include_docvars = TRUE)
```

```{r}
lower_UNGD <- tokens_tolower(toks_UNGD)
stop_UNGD <- tokens_select(lower_UNGD, stopwords("english"), selection = "remove", padding = FALSE)
ngram_UNGD <- tokens(stop_UNGD, ngrams = c(1:2), include_docvars = TRUE) 
 
```

#Dictionary Analysis HR binary
## Stage 1 - Human Rights terms

Creating compound tokens from the key terms identified:

```{r}
listHHRR <- list( c("Human", "Rights")) 
```


```{r}
compound_UNGD <- tokens_compound(lower_UNGD, listHHRR, valuetype = "fixed", concatenator = "_")
```

Creating the dictionary object of Human Rights terms:

```{r}
HHRR_dict <- dictionary(list(Human.Rights=c("Human Rights")))
```

## Look up Human Rights term counts

Looking up and counting terms from Human Rights in the DFM

DFM_LOOKUP --> Apply a dictionary (HHRR) to a dfm by looking up all dfm features for matches in a a set of dictionary values, and replace those features with a count of the dictionary's keys.

```{r}
dfm_UNGD <- dfm(compound_UNGD)
HHRR_dfm <- dfm_lookup(dfm_UNGD, HHRR_dict, valuetype = "fixed")
```

```{r}
head(HHRR_dfm)
```

Data Frame of human rights variables in UNGDC

```{r}
#creating a data frame 
Human.Rights <- convert(HHRR_dfm, to = "data.frame")

#converting documentID into two columns - country and year
HHRR_counts <- Human.Rights %>%
  separate(document, c("country", "year"), "_")

#year as numeric
HHRR_counts$year <- as.numeric(HHRR_counts$year)
HHRR_counts <- plyr::rename(HHRR_counts, c("Human.Rights"="HHRR"))
```

```{r}
head(HHRR_counts)
```


Presentation of results
Map for 2017 of HHRR

Keeping only country-years with at least one mention of HHRR


```{r}
mentions_HHRR <- subset(HHRR_counts, HHRR!=0)
```

```{r}
head(mentions_HHRR)
```



Error in joinCountryData2Map --> check the packages

```{r}
map <- joinCountryData2Map(subset(mentions_HHRR, year==2017), joinCode="ISO3", nameJoinColumn="country")
new_world <- subset(map, continent != "Antarctica")
pdf("worldmap_2017_health.pdf", width = 7, height = 3)
par(mai=c(0,0,0.2,0),xaxs="i",yaxs="i")
mapParams <- mapCountryData(new_world, nameColumnToPlot="HHRR", 
                            mapTitle="2017 UN General Debate: HHRR", 
                            catMethod = "categorical", 
                            colourPalette = "heat", 
                            oceanCol = "lightblue", 
                            missingCountryCol = "white", 
                            addLegend="FALSE")
do.call( addMapLegendBoxes, c(mapParams,title="Number of mentions", x = "left", cex=0.5))
dev.off()
```

## Time series of total counts plot

### Total counts

```{r}
?country2Region
```


```{r}
# calculating the total number of mentions by year
sum <- summarise(group_by(country2Region(count), year), count = sum(Human.Rights), mean = mean(Human.Rights))
ggplot(sum, aes(x=year)) +
  theme_bw() +
  geom_line(aes(y= HHRR_count), colour = "blue", alpha = 0.9) +
  ylab("Total number of references per UNGD session") + xlab("Year") + 
#  scale_y_continuous(limits=c(0, 140), breaks = c(1, 50, 100, 134)) +
  scale_x_continuous(limits=c(1970, 2017), breaks = c(1970, 1988, 2000, 2009,2014, 2017)) +
   annotate("text", x = 1993, y = 250, label = "Human Rights", colour = "blue")
```

regression
reg HHRR changeinPTS PTS_year PTS_year * changeinPTS, 
reg HHRR changeinPTS PTS_year PTS_year * changeinPTS, clustered errors
reg HHRR changeinPTS PTS_year PTS_year * changeinPTS, time-fixed effects, country-fixed effects, clustered errors


